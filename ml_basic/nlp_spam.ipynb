{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "857c53d5-4cc2-4423-9dfa-f28e2366c6eb",
   "metadata": {},
   "source": [
    "## Spam detection NLP binary classification\n",
    "\n",
    "dataset source:  \n",
    "https://www.kaggle.com/datasets/purusinghvi/email-spam-classification-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb4ecf58-840d-496c-b426-5f525947287c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\programowanie_web_etc\\python_projects\\ml_projects\\ml_basic\\venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44112ade-315b-414f-917e-abfe81df49b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = './big_datasets/spam_emails/combined_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "381f328a-439b-4a70-b971-db695901b47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_df =  pd.read_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "537b14d8-87e7-49bc-9ce8-95962da041e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ounce feather bowl hummingbird opec moment ala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>wulvob get your medircations online qnb ikud v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>computer connection from cnn com wednesday es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>university degree obtain a prosperous future m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>thanks for all your answers guys i know i shou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  ounce feather bowl hummingbird opec moment ala...\n",
       "1      1  wulvob get your medircations online qnb ikud v...\n",
       "2      0   computer connection from cnn com wednesday es...\n",
       "3      1  university degree obtain a prosperous future m...\n",
       "4      0  thanks for all your answers guys i know i shou..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b987460f-3d5a-495b-85f7-812ab665d170",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_df_shuffled = spam_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c756aa86-a91c-4a2b-a7fc-68a05b4999cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
    "    spam_df_shuffled['text'].to_numpy(),\n",
    "    spam_df['label'].to_numpy(),\n",
    "    test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96079588-3104-4b11-9043-e85a75a9b64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75103, 8345)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences), len(val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fea3a250-a59c-4876-8c4a-95fbc020d3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find average number of tokens (words) in training Tweets\n",
    "avg_words = round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "634687bb-9409-4c64-9e94-a1934e9b50de",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_len = 20000\n",
    "max_sentence_len = avg_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76652edb-1a09-43f9-8b4c-28c03f24b588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2efa73b-9139-4cbe-b937-7bc89877f898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\programowanie_web_etc\\python_projects\\ml_projects\\ml_basic\\venv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# here we're initializing a tokenizer with a set output sequence lenght (to help with batching)\n",
    "# plus we're setting max_tokens to limit the tokens considered to the 10000 most common ones\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_len,\n",
    "                                    standardize=\"lower_and_strip_punctuation\",\n",
    "                                    split=\"whitespace\",\n",
    "                                    ngrams=None,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_sentence_len\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "697eff9a-1829-44cf-b414-af85ca21b6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\programowanie_web_etc\\python_projects\\ml_projects\\ml_basic\\venv\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9bb2d2-7d46-4181-a848-1b71bb0476ee",
   "metadata": {},
   "source": [
    "#### Pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c661e472-4261-439a-b851-601526e20579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\programowanie_web_etc\\python_projects\\ml_projects\\ml_basic\\venv\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py:74: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\programowanie_web_etc\\python_projects\\ml_projects\\ml_basic\\venv\\lib\\site-packages\\tensorflow_hub\\native_module.py:92: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\programowanie_web_etc\\python_projects\\ml_projects\\ml_basic\\venv\\lib\\site-packages\\tensorflow_hub\\saved_model_module.py:40: The name tf.saved_model.constants.LEGACY_INIT_OP_KEY is deprecated. Please use tf.compat.v1.saved_model.constants.LEGACY_INIT_OP_KEY instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\programowanie_web_etc\\python_projects\\ml_projects\\ml_basic\\venv\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\programowanie_web_etc\\python_projects\\ml_projects\\ml_basic\\venv\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\programowanie_web_etc\\python_projects\\ml_projects\\ml_basic\\venv\\lib\\site-packages\\tensorflow_hub\\module_v2.py:120: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\programowanie_web_etc\\python_projects\\ml_projects\\ml_basic\\venv\\lib\\site-packages\\tensorflow_hub\\module_v2.py:120: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example of pretrained embedding with universal sentence encoder - https://tfhub.dev/google/universal-sentence-encoder/4\n",
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e95402f7-b15e-4fd5-aaa4-a8c91b2e2f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "x = hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4', \n",
    "                    trainable=False)(inputs)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "model_use = tf.keras.models.Model(inputs, outputs, name=\"model_6_USE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f7218db-9d5a-4015-a8f4-d3e501075e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None,)]                 0         \n",
      "                                                                 \n",
      " keras_layer (KerasLayer)    (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256830721 (979.73 MB)\n",
      "Trainable params: 32897 (128.50 KB)\n",
      "Non-trainable params: 256797824 (979.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model_use.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_use.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ca13448-01cb-40c1-9a19-5fd2203052ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2347/2347 [==============================] - 88s 37ms/step - loss: 0.6923 - accuracy: 0.5233 - val_loss: 0.6916 - val_accuracy: 0.5299\n",
      "Epoch 2/5\n",
      "2347/2347 [==============================] - 87s 37ms/step - loss: 0.6911 - accuracy: 0.5291 - val_loss: 0.6918 - val_accuracy: 0.5282\n",
      "Epoch 3/5\n",
      "2347/2347 [==============================] - 86s 37ms/step - loss: 0.6892 - accuracy: 0.5348 - val_loss: 0.6937 - val_accuracy: 0.5152\n",
      "Epoch 4/5\n",
      "2347/2347 [==============================] - 86s 36ms/step - loss: 0.6856 - accuracy: 0.5464 - val_loss: 0.6951 - val_accuracy: 0.5165\n",
      "Epoch 5/5\n",
      "2347/2347 [==============================] - 86s 36ms/step - loss: 0.6804 - accuracy: 0.5589 - val_loss: 0.6983 - val_accuracy: 0.5104\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on top of pretrained embeddings\n",
    "model_use_history = model_use.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a28d84c5-d86d-49d1-ae55-f410f571b532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "\n",
    "  Args:\n",
    "  -----\n",
    "  y_true = true labels in the form of a 1D array\n",
    "  y_pred = predicted labels in the form of a 1D array\n",
    "\n",
    "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
    "  \"\"\"\n",
    "  # Calculate model accuracy\n",
    "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
    "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "  model_results = {\"accuracy\": model_accuracy,\n",
    "                  \"precision\": model_precision,\n",
    "                  \"recall\": model_recall,\n",
    "                  \"f1\": model_f1}\n",
    "  return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "333a234c-628a-4339-8067-bf1d96c58f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 8s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 51.036548831635706,\n",
       " 'precision': 0.49947542512182286,\n",
       " 'recall': 0.5103654883163571,\n",
       " 'f1': 0.48903435318569755}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with USE TF Hub model\n",
    "model_use_pred_probs = model_use.predict(val_sentences)\n",
    "# Convert prediction probabilities to labels\n",
    "model_use_preds = tf.squeeze(tf.round(model_use_pred_probs))\n",
    "# Calculate model use performance metrics\n",
    "model_use_results = calculate_results(val_labels, model_use_preds)\n",
    "model_use_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "ml_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
