{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2af13c68-e2ca-4690-858c-0f85c1fa3b40",
   "metadata": {},
   "source": [
    "## NLP beginning exercises\n",
    "Including:\n",
    "* Tokenization\n",
    "* Embedding\n",
    "* Different types of layers/nets\n",
    "* Functional keras\n",
    "\n",
    "based on: https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec335270-128a-42e0-a9c9-464110fc0103",
   "metadata": {},
   "source": [
    "### Dataset loading an imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3aaab32-ee6a-4250-854a-36085663e531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c6363d4-d2de-4b13-b516-6a8561db9137",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './datasets/nlp_disaster/train.csv'\n",
    "test_path = './datasets/nlp_disaster/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a40cb46c-23c9-4d4f-90a0-dc798fd87da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5c3a7df-0f3b-4fe6-bc2a-acdca8e9223c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4a045f6-f6e5-4444-8492-f0e5ee447fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>6026</td>\n",
       "      <td>hazardous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MTR issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6802</th>\n",
       "      <td>9745</td>\n",
       "      <td>tragedy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Robert Gagnon reviews the catastrophe of impos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5099</th>\n",
       "      <td>7274</td>\n",
       "      <td>nuclear%20disaster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3 Former Executives To Be Prosecuted In Fukush...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>1905</td>\n",
       "      <td>burning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@nagel_ashley @Vicken52 @BasedLaRock @goonc1ty...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>1045</td>\n",
       "      <td>bleeding</td>\n",
       "      <td>dmv ?? fashion school @ KSU.</td>\n",
       "      <td>i hit my foot now my toe is bleeding ??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id             keyword                       location  \\\n",
       "4241  6026           hazardous                            NaN   \n",
       "6802  9745             tragedy                            NaN   \n",
       "5099  7274  nuclear%20disaster                            NaN   \n",
       "1318  1905             burning                            NaN   \n",
       "724   1045            bleeding  dmv ?? fashion school @ KSU.    \n",
       "\n",
       "                                                   text  target  \n",
       "4241  MTR issues Hazardous Weather Outlook (HWO) htt...       1  \n",
       "6802  Robert Gagnon reviews the catastrophe of impos...       1  \n",
       "5099  3 Former Executives To Be Prosecuted In Fukush...       1  \n",
       "1318  @nagel_ashley @Vicken52 @BasedLaRock @goonc1ty...       0  \n",
       "724             i hit my foot now my toe is bleeding ??       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_shuffled = train_df.sample(frac=1)\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55f1b6d1-0bcd-4a12-af66-46e63122cb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    4342\n",
       "1    3271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61aed55-6d06-46ae-978f-4e4e4c18fb40",
   "metadata": {},
   "source": [
    "### Visualize random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f88d094d-cd23-4a8e-a907-83680911e720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: disaster\n",
      "\n",
      "#computers #gadgets Two giant cranes holding a bridge collapse into nearby homes http://t.co/UZIWgZRynY #slingnews\n",
      "\n",
      "---\n",
      "\n",
      "target: not disaster\n",
      "\n",
      "Reddit Will Now Quarantine Offensive Content http://t.co/LOdOrmTfSq\n",
      "\n",
      "---\n",
      "\n",
      "target: disaster\n",
      "\n",
      "b/c it costs less to have sick people using emergency rooms?...grrrr.... http://t.co/vFbbcHwrFD\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_index = random.randint(0, len(train_df)-3)\n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+3].itertuples():\n",
    "    ind, text, target = row\n",
    "    print(f'target: {\"disaster\" if target > 0 else \"not disaster\"}')\n",
    "    print(f'\\n{text}\\n')\n",
    "    # print(f'ind: {ind}')\n",
    "    print('---\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136d9a08-75a8-458b-b73b-0f423ef36616",
   "metadata": {},
   "source": [
    "### Create a validation set as the test set is for competition entrances, and it doesn't have a target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4638ed5e-1e18-4c07-bea1-885bca048b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
    "    train_df_shuffled['text'].to_numpy(),\n",
    "    train_df_shuffled['target'].to_numpy(),\n",
    "    test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45608110-f629-4415-ad28-51e527600918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 762)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences), len(val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02724a10-77d5-49de-b539-54b0b4437a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3293c33b-18dc-48df-ad2f-b5613f06c4c3",
   "metadata": {},
   "source": [
    "#### Text vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98a85a23-0e16-4963-940a-d34492f56b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find average number of tokens (words) in training Tweets\n",
    "avg_words = round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c2752ae-595d-4557-ab84-0d89fce15386",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_len = 10000\n",
    "max_sentence_len = avg_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8967226-d707-43ff-bff8-053dca4b6b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we're initializing a tokenizer with a set output sequence lenght (to help with batching)\n",
    "# plus we're setting max_tokens to limit the tokens considered to the 10000 most common ones\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_len,\n",
    "                                    standardize=\"lower_and_strip_punctuation\",\n",
    "                                    split=\"whitespace\",\n",
    "                                    ngrams=None,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_sentence_len\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cedc98-146f-41a4-ab84-4acdf2d98939",
   "metadata": {},
   "source": [
    "##### you have to fit (adapt) a vectorizer to your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eeacf239-1f7a-44df-a22a-9ff8f2e9aebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "468f212f-fc7a-4e74-ae23-6e65967b195c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are people not concerned that after #SLAB's obliteration in Scotland #Labour UK is ripping itself apart over #Labourleadership contest?\n",
      "tf.Tensor(\n",
      "[[  21   57   33 1704   17   38 8393  511    4 3429 5200  981    9 9034\n",
      "  2084]], shape=(1, 15), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# test the vectorizer\n",
    "sample_sentence = random.choice(train_sentences)\n",
    "print(sample_sentence)\n",
    "print(text_vectorizer([sample_sentence]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be4ddd1c-f013-4c29-aac4-986d3d220c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 10000\n",
      "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
      "Bottom 5 least common words: ['ovofest', 'ovo', 'overåÊhostages', 'overzero', 'overwhelming']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
    "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
    "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
    "print(f\"Top 5 most common words: {top_5_words}\") \n",
    "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba407c4-ffe4-4f1e-bded-8cd506352122",
   "metadata": {},
   "source": [
    "#### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92543f6e-c8d1-4d20-8603-88f4a6a4c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34e7420a-0f14-4a85-a829-84e21b11820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len of embedding vectors\n",
    "embed_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d31dc9ea-32dd-4d77-aa25-b0fb67b87db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.core.embedding.Embedding at 0x1f08d545b10>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = layers.Embedding(input_dim=max_vocab_len, # set input shape\n",
    "                             output_dim=embed_len, # set size of embedding vector\n",
    "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
    "                             input_length=max_sentence_len, # how long is each input\n",
    "                             name=\"embedding_1\") \n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "56e18e54-9065-408b-9aa1-841c68dd8489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would like to electrocute everyone who uses the word 'fair' in connection with income tax policies. - William F. Buckley Jr.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[ 0.0486181 ,  0.04681425,  0.01941798, ..., -0.0259532 ,\n",
       "         -0.03178634,  0.03056673],\n",
       "        [-0.03503084, -0.03483643, -0.03200938, ..., -0.0245998 ,\n",
       "          0.0182102 , -0.00779082],\n",
       "        [-0.04591447, -0.04023138, -0.04675725, ..., -0.02857027,\n",
       "         -0.00123527,  0.02125475],\n",
       "        ...,\n",
       "        [ 0.0182826 ,  0.01587267, -0.02455018, ...,  0.04657182,\n",
       "         -0.0348844 , -0.04203259],\n",
       "        [ 0.02937689,  0.01791295, -0.04557009, ...,  0.01946897,\n",
       "         -0.0269248 ,  0.00549157],\n",
       "        [ 0.04779092,  0.01424534, -0.0093229 , ..., -0.04571698,\n",
       "         -0.02980891, -0.04442218]]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the embedder\n",
    "# each tokken gets embedded into a vector\n",
    "sample_sentence = random.choice(train_sentences)\n",
    "print(sample_sentence)\n",
    "sample_embed = embedding(text_vectorizer([sample_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b789bb7-320f-4c22-b73c-024b15b5ef17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 15, 128])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7660e57-1c62-4475-ad1f-8408bce9647e",
   "metadata": {},
   "source": [
    "### Baseline model - tf/idf term weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "328cad4d-b7f7-4b3b-bf1b-4427efb1c9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenization and modelling pipeline\n",
    "model_0 = Pipeline([\n",
    "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
    "                    (\"clf\", MultinomialNB()) # model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f2479b4c-11c6-4aef-96bf-24985dc2fb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline model achieves an accuracy of: 77.95%\n"
     ]
    }
   ],
   "source": [
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48e6d27-6033-4564-a160-066baa9e7e62",
   "metadata": {},
   "source": [
    "### Function to evaluate models on a classification task\n",
    "with accuracy, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c681b006-a99e-4813-96f9-554c95ff007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "\n",
    "  Args:\n",
    "  -----\n",
    "  y_true = true labels in the form of a 1D array\n",
    "  y_pred = predicted labels in the form of a 1D array\n",
    "\n",
    "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
    "  \"\"\"\n",
    "  # Calculate model accuracy\n",
    "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
    "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "  model_results = {\"accuracy\": model_accuracy,\n",
    "                  \"precision\": model_precision,\n",
    "                  \"recall\": model_recall,\n",
    "                  \"f1\": model_f1}\n",
    "  return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "555ecd7f-cb4f-47d7-9ae0-26237dde7358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.95275590551181,\n",
       " 'precision': 0.7915472508475033,\n",
       " 'recall': 0.7795275590551181,\n",
       " 'f1': 0.7694175813079408}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get baseline results\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "\n",
    "baseline_results = calculate_results(y_true=val_labels,\n",
    "                                     y_pred=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4dfe57-e06b-4c62-b4f8-e44078bdff2a",
   "metadata": {},
   "source": [
    "### A simple Dense model\n",
    "(functional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "14848635-88bf-443f-b305-02049845ae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs are 1D vectors of dtype=\"string\" [validation]\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "# vectorize\n",
    "x = text_vectorizer(inputs)\n",
    "# embed\n",
    "x = embedding(x)\n",
    "# embedding returns (1,15,128) - 15 for each token, 128 for vector len,\n",
    "# we want a prediction for the whole sentence so we have to compile these results\n",
    "# with average or max pooling (1D)\n",
    "x = layers.GlobalAveragePooling1D()(x) #(x) outside as per documentation\n",
    "# binary classification therefore 1 output neuron and sigmoid\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# create model from functional layers\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "84b3bb31-3a7c-4df0-96dd-c0c26060002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f26917a-6d15-495c-bf11-6605cde9884e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_4 (Text  (None, 15)                0         \n",
      " Vectorization)                                                  \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d_1  (None, 128)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1280129 (4.88 MB)\n",
      "Trainable params: 1280129 (4.88 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "76cb3455-5e0e-4a5d-9540-de9a6e63ccf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\programowanie_web_etc\\python_projects\\ml_projects\\ml_basic\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "215/215 [==============================] - 2s 6ms/step - loss: 0.6127 - accuracy: 0.6945 - val_loss: 0.5393 - val_accuracy: 0.7546\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.4425 - accuracy: 0.8162 - val_loss: 0.4727 - val_accuracy: 0.7913\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.3497 - accuracy: 0.8602 - val_loss: 0.4562 - val_accuracy: 0.7979\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.2871 - accuracy: 0.8899 - val_loss: 0.4557 - val_accuracy: 0.7927\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.2399 - accuracy: 0.9120 - val_loss: 0.4704 - val_accuracy: 0.7940\n"
     ]
    }
   ],
   "source": [
    "model_1_history = model_1.fit(x=train_sentences,\n",
    "                              y=train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5ec3de-8e66-41ee-83f0-a9b58430650e",
   "metadata": {},
   "source": [
    "#### Model results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f784d07-74b7-44d2-8b12-b094816caf08",
   "metadata": {},
   "source": [
    "#### Important note: As we're using a sigmoid output, to get prediction classes, we need to round the prediction values (probabilities) [or in multiclass choose the highest one from the prediction prob array and then round]\n",
    "then also squeeze the dimension for comparison reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "19ed9a75-d9ea-45cd-a325-b84851c9c62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 913us/step\n"
     ]
    }
   ],
   "source": [
    "model_1_preds = tf.squeeze(tf.round(model_1.predict(val_sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "97d73ff9-a2c5-49d7-bd97-c41ab9e0ddb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 1., 1., 0., 0., 0., 0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9d5c843c-ad44-47ea-a392-9d390d885d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.39632545931758,\n",
       " 'precision': 0.7928903507036981,\n",
       " 'recall': 0.7939632545931758,\n",
       " 'f1': 0.7920589507063273}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 metrics\n",
    "model_1_results = calculate_results(y_true=val_labels, \n",
    "                                    y_pred=model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "24462b5a-d200-4269-8326-d4a5bbe9b8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 77.95, New accuracy: 79.40, Difference: 1.44\n",
      "Baseline precision: 0.79, New precision: 0.79, Difference: 0.00\n",
      "Baseline recall: 0.78, New recall: 0.79, Difference: 0.01\n",
      "Baseline f1: 0.77, New f1: 0.79, Difference: 0.02\n"
     ]
    }
   ],
   "source": [
    "# Create a helper function to compare our baseline results to new model results\n",
    "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
    "  for key, value in baseline_results.items():\n",
    "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
    "\n",
    "compare_baseline_to_new_results(baseline_results=baseline_results, \n",
    "                                new_model_results=model_1_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdd92b9-1951-4873-80b3-634449bd60db",
   "metadata": {},
   "source": [
    "### RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d0f745-e1d9-40b4-b838-b518ebe6ce7c",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8d6aa6-8919-499b-a099-36bc56615b03",
   "metadata": {},
   "source": [
    "#### Note: because we use embeddings as layers, they get trained during model fitting\n",
    "to combat that, we have to create a separate embedding layer for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "08d0898d-7169-46d9-a7db-dc4ef491358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_embedding = layers.Embedding(input_dim=max_vocab_len, # set input shape\n",
    "                             output_dim=embed_len, # set size of embedding vector\n",
    "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
    "                             input_length=max_sentence_len, # how long is each input\n",
    "                             name=\"embedding_2\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1fda944a-48d6-450a-a1e1-e9bed5198a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_2_embedding(x)\n",
    "x = layers.LSTM(units=64)(x)\n",
    "# x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN layers)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "11d377a2-5e7c-4d0c-8a53-f9ddaa365881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_2.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "806e72e6-7507-4a06-a610-1110b4c5ed79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_4 (Text  (None, 15)                0         \n",
      " Vectorization)                                                  \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1329473 (5.07 MB)\n",
      "Trainable params: 1329473 (5.07 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "742705a4-0069-441c-9f27-9fa428d90e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 3s 10ms/step - loss: 0.5057 - accuracy: 0.7484 - val_loss: 0.4769 - val_accuracy: 0.7848\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.3191 - accuracy: 0.8675 - val_loss: 0.4589 - val_accuracy: 0.7979\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.2200 - accuracy: 0.9161 - val_loss: 0.5938 - val_accuracy: 0.7703\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1565 - accuracy: 0.9425 - val_loss: 0.6723 - val_accuracy: 0.7664\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1053 - accuracy: 0.9610 - val_loss: 0.9579 - val_accuracy: 0.7362\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "model_2_history = model_2.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "75234546-ea00-4e53-b9e1-1b0ba1d42669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 73.62204724409449,\n",
       " 'precision': 0.7434830367281546,\n",
       " 'recall': 0.7362204724409449,\n",
       " 'f1': 0.7379301831916483}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "# Round out predictions and reduce to 1-dimensional array\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "# Calculate LSTM model results\n",
    "model_2_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_2_preds)\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea2eaae-e990-4817-8237-babcd388f56b",
   "metadata": {},
   "source": [
    "### Other RNN layers to try: GRU, Bidirectional RNN/LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7496ba73-687c-4f81-aa4a-3ab50eed3842",
   "metadata": {},
   "source": [
    "### Could also use 1D CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db8ac30-da3b-4930-911a-5e67e99afe65",
   "metadata": {},
   "source": [
    "### Pretrained embeddings / transfer learning for NLP\n",
    "\n",
    "https://tfhub.dev/google/universal-sentence-encoder/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "48eab007-16e5-48a2-95ef-d44d1f6bf04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\programowanie_web_etc\\python_projects\\ml_projects\\ml_basic\\venv\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py:74: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\programowanie_web_etc\\python_projects\\ml_projects\\ml_basic\\venv\\lib\\site-packages\\tensorflow_hub\\saved_model_module.py:40: The name tf.saved_model.constants.LEGACY_INIT_OP_KEY is deprecated. Please use tf.compat.v1.saved_model.constants.LEGACY_INIT_OP_KEY instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\programowanie_web_etc\\python_projects\\ml_projects\\ml_basic\\venv\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\programowanie_web_etc\\python_projects\\ml_projects\\ml_basic\\venv\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\programowanie_web_etc\\python_projects\\ml_projects\\ml_basic\\venv\\lib\\site-packages\\tensorflow_hub\\module_v2.py:120: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\programowanie_web_etc\\python_projects\\ml_projects\\ml_basic\\venv\\lib\\site-packages\\tensorflow_hub\\module_v2.py:120: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 0.03491368 -0.05202626 -0.0165102  -0.08337957 -0.01891575 -0.07866167\n",
      " -0.05584712 -0.05938221  0.02887729 -0.06164343  0.00379627 -0.0170562\n",
      " -0.02297798 -0.04288733 -0.0446399  -0.07259919 -0.03284239  0.00814521\n",
      " -0.06901841 -0.00363603 -0.05164122 -0.02577795  0.03388479 -0.0409942\n",
      " -0.07960071  0.02076143  0.0700054   0.01461454  0.04525214 -0.02656616\n",
      "  0.00033423 -0.04028461  0.0391934   0.05764904 -0.00947513 -0.05555471\n",
      "  0.06020658 -0.01631964  0.00075163 -0.03646719  0.05976842 -0.06878553\n",
      "  0.03679937  0.02036367  0.00862888  0.07077238 -0.05169178 -0.05026665\n",
      " -0.05757866 -0.08680485], shape=(50,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Example of pretrained embedding with universal sentence encoder - https://tfhub.dev/google/universal-sentence-encoder/4\r\n",
    "import tensorflow_hub as hub\r\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load Universal Sentence Encoder\r\n",
    "embed_samples = embed([sample_sentence,\r\n",
    "                      \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\r\n",
    "\r\n",
    "print(embed_samples[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e15b38ac-e5f2-4345-b353-4c5659f1928f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([512])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_samples[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686c52cd-514c-412a-88a6-e044d149289f",
   "metadata": {},
   "source": [
    "#### The downloaded pre-trained weights are the encoder\n",
    "let's create a layer based on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "40a3a87a-aa32-42c8-a0a1-9cdf0195c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use this encoding layer in place of our text_vectorizer and embedding layer\n",
    "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        input_shape=[], # shape of inputs coming to our model \n",
    "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
    "                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
    "                                        name=\"USE\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547cd0bc-7277-418c-b5ab-9f0cf387b0b1",
   "metadata": {},
   "source": [
    "Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780e415a-20cc-4a70-af6b-0389934225fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model using the Sequential API\n",
    "# model_6 = tf.keras.Sequential([\n",
    "#   sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
    "#   layers.Dense(64, activation=\"relu\"),\n",
    "#   layers.Dense(1, activation=\"sigmoid\")\n",
    "# ], name=\"model_6_USE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01283b7-02e6-4cca-8dd6-2f9900052cf5",
   "metadata": {},
   "source": [
    "Functional attempt 1 (nvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9d0ad57e-a47f-46fa-b337-3ffd8cbaa44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = layers.Input(input_shape=(1,), dtype=\"string\"\n",
    "# no inputs layer, already included in the encoding layer\n",
    "# inputs = sentence_encoder_layer\n",
    "# x = layers.Dense(64, activation='relu')(x)\n",
    "# outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# model_6 = tf.keras.Model(inputs, outputs, name=\"model_6_USE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dd28f9-ac8e-4f42-8de4-2e188debf790",
   "metadata": {},
   "source": [
    "https://www.dlology.com/blog/keras-meets-universal-sentence-encoder-transfer-learning-for-text-data/\n",
    "\n",
    "Functional attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d7c6dcf2-caa5-4c60-a6a1-22066a3d5352",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "x = hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4', \n",
    "                    trainable=False)(inputs)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "model_6 = tf.keras.models.Model(inputs, outputs, name=\"model_6_USE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dcbd21dc-9b35-47ab-9c88-fa7bd0964b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None,)]                 0         \n",
      "                                                                 \n",
      " keras_layer_1 (KerasLayer)  (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256830721 (979.73 MB)\n",
      "Trainable params: 32897 (128.50 KB)\n",
      "Non-trainable params: 256797824 (979.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model_6.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8deef59a-64f9-4504-88cf-c2727086bfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 3s 5ms/step - loss: 0.5050 - accuracy: 0.7876 - val_loss: 0.4475 - val_accuracy: 0.7979\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.4156 - accuracy: 0.8158 - val_loss: 0.4336 - val_accuracy: 0.7979\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.4018 - accuracy: 0.8219 - val_loss: 0.4275 - val_accuracy: 0.8018\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.3926 - accuracy: 0.8270 - val_loss: 0.4246 - val_accuracy: 0.8058\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.3856 - accuracy: 0.8308 - val_loss: 0.4208 - val_accuracy: 0.8097\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on top of pretrained embeddings\n",
    "model_6_history = model_6.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c86236ad-41be-408b-ac5d-778690a81e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 80.97112860892388,\n",
       " 'precision': 0.809695567195205,\n",
       " 'recall': 0.8097112860892388,\n",
       " 'f1': 0.8072289690741726}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with USE TF Hub model\n",
    "model_6_pred_probs = model_6.predict(val_sentences)\n",
    "# Convert prediction probabilities to labels\n",
    "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
    "# Calculate model 6 performance metrics\n",
    "model_6_results = calculate_results(val_labels, model_6_preds)\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8d3990-ccfd-490a-ac2e-2f4bad30e66b",
   "metadata": {},
   "source": [
    "### Compare model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1d2e9a85-99a2-4373-99cb-ffa163f91d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>77.952756</td>\n",
       "      <td>0.791547</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.769418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple_dense</th>\n",
       "      <td>79.396325</td>\n",
       "      <td>0.792890</td>\n",
       "      <td>0.793963</td>\n",
       "      <td>0.792059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <td>73.622047</td>\n",
       "      <td>0.743483</td>\n",
       "      <td>0.736220</td>\n",
       "      <td>0.737930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_sentence_encoder</th>\n",
       "      <td>80.971129</td>\n",
       "      <td>0.809696</td>\n",
       "      <td>0.809711</td>\n",
       "      <td>0.807229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          accuracy  precision    recall        f1\n",
       "baseline                 77.952756   0.791547  0.779528  0.769418\n",
       "simple_dense             79.396325   0.792890  0.793963  0.792059\n",
       "lstm                     73.622047   0.743483  0.736220  0.737930\n",
       "tf_hub_sentence_encoder  80.971129   0.809696  0.809711  0.807229"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine model results into a DataFrame\n",
    "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
    "                                  \"simple_dense\": model_1_results,\n",
    "                                  \"lstm\": model_2_results,\n",
    "                                  \"tf_hub_sentence_encoder\": model_6_results,\n",
    "                                  })\n",
    "all_model_results = all_model_results.transpose()\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "92074565-03d7-4617-afcc-91ba80a5935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the accuracy to same scale as other metrics\n",
    "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "91461146-0ec6-4784-a0bc-e2dcf3d820b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot and compare all of the model results\n",
    "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1fbc8d-48d6-4a40-95b9-36002d54dcbe",
   "metadata": {},
   "source": [
    "### Extra - model ensembling\n",
    "using averaging of predictions from out multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e515fe59-1bbb-44e5-857c-b94e0a17ecaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c4af3eb7-9bb8-48cb-b3b7-468375191a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get mean pred probs for 3 models\n",
    "baseline_pred_probs = np.max(model_0.predict_proba(val_sentences), axis=1) # get the prediction probabilities from baseline model\n",
    "combined_pred_probs = baseline_pred_probs + tf.squeeze(model_2_pred_probs, axis=1) + tf.squeeze(model_6_pred_probs)\n",
    "combined_preds = tf.round(combined_pred_probs/3) # average and round the prediction probabilities to get prediction classes\n",
    "combined_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3575309e-006d-4dd8-b531-c71aab3a1336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 74.80314960629921,\n",
       " 'precision': 0.7675144733356206,\n",
       " 'recall': 0.7480314960629921,\n",
       " 'f1': 0.74993726780156}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate results from averaging the prediction probabilities\n",
    "ensemble_results = calculate_results(val_labels, combined_preds)\n",
    "ensemble_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a404788-5033-4105-99ef-0faed4cf22a5",
   "metadata": {},
   "source": [
    "#### In our case - not really an improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17fd783-3511-45e1-a248-d0194c8d971c",
   "metadata": {},
   "source": [
    "### Save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9b37e8d7-741e-4cb2-bb82-33a7c7b1fd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_6_USE_distaster\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_6_USE_distaster\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save TF Hub Sentence Encoder model to HDF5 format\n",
    "model_6.save(\"model_6_USE_distaster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c528a068-8a19-4777-addb-2cb26bfff654",
   "metadata": {},
   "source": [
    "### Additional prediction / performance explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "86e9dfca-e29f-438c-95d4-9153a30fc34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@RyleeDowns02 @nevaehburton33 if I don't get m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.241386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A deluge of eulogies  for #CecilTheLion on my ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An Eau Claire man who police said was drunk wh...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images of Famine ÛÒ Hope In Christ - A blog o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.364708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#PBBan (Temporary:300) fighterdena @'aRmageddo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.651767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  pred  pred_prob\n",
       "0  @RyleeDowns02 @nevaehburton33 if I don't get m...       0   0.0   0.241386\n",
       "1  A deluge of eulogies  for #CecilTheLion on my ...       0   0.0   0.144588\n",
       "2  An Eau Claire man who police said was drunk wh...       1   1.0   0.976626\n",
       "3  Images of Famine ÛÒ Hope In Christ - A blog o...       1   0.0   0.364708\n",
       "4  #PBBan (Temporary:300) fighterdena @'aRmageddo...       0   1.0   0.651767"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe with validation sentences and best performing model predictions\n",
    "val_df = pd.DataFrame({\"text\": val_sentences,\n",
    "                       \"target\": val_labels,\n",
    "                       \"pred\": model_6_preds,\n",
    "                       \"pred_prob\": tf.squeeze(model_6_pred_probs)})\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d3383d4e-008b-4573-86fe-f38f1fe97af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>09:13 PM:  Hazardous Weather Outlook (http://t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Beautiful lightning as seen from plane window ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>The first trial in the death of #CecilTheLion ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.892217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>@CNN the End of Times are upon us. Famine War ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.868433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Google Alert: Emergency units simulate a chemi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>On plus side LOOK AT THE SKY LAST NIGHT IT WAS...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.841473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>On Thursday at 00:25 we updated our #kml of 2D...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.818817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>http://t.co/eHKLp12yiP Paci?c Media Centre | a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.810652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>Do you want to play a game?\\nhttp://t.co/sQFp6...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.809695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  target  pred  \\\n",
       "535  09:13 PM:  Hazardous Weather Outlook (http://t...       0   1.0   \n",
       "710  ? High Skies - Burning Buildings ? http://t.co...       0   1.0   \n",
       "133  Beautiful lightning as seen from plane window ...       0   1.0   \n",
       "151  The first trial in the death of #CecilTheLion ...       0   1.0   \n",
       "683  @CNN the End of Times are upon us. Famine War ...       0   1.0   \n",
       "154  Google Alert: Emergency units simulate a chemi...       0   1.0   \n",
       "458  On plus side LOOK AT THE SKY LAST NIGHT IT WAS...       0   1.0   \n",
       "747  On Thursday at 00:25 we updated our #kml of 2D...       0   1.0   \n",
       "203  http://t.co/eHKLp12yiP Paci?c Media Centre | a...       0   1.0   \n",
       "319  Do you want to play a game?\\nhttp://t.co/sQFp6...       0   1.0   \n",
       "\n",
       "     pred_prob  \n",
       "535   0.911499  \n",
       "710   0.909534  \n",
       "133   0.902969  \n",
       "151   0.892217  \n",
       "683   0.868433  \n",
       "154   0.863457  \n",
       "458   0.841473  \n",
       "747   0.818817  \n",
       "203   0.810652  \n",
       "319   0.809695  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the wrong predictions and sort by prediction probabilities\n",
    "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\n",
    "most_wrong[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d13cbb16-3f9b-4592-bed8-1f07129e10e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0, Pred: 1, Prob: 0.9114993810653687\n",
      "Text:\n",
      "09:13 PM:  Hazardous Weather Outlook (http://t.co/ed1VpITsWY): NO HAZARDOUS WEATHER IS EXPECTED AT THIS TIME.... http://t.co/6XSbddlZiy\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.9095335006713867\n",
      "Text:\n",
      "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.9029689431190491\n",
      "Text:\n",
      "Beautiful lightning as seen from plane window http://t.co/5CwUyLnFUm http://t.co/1tyYqFz13D\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8922174572944641\n",
      "Text:\n",
      "The first trial in the death of #CecilTheLion was just postponed http://t.co/fnmJE8GF7m http://t.co/nYe8ae2ifr\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8684331774711609\n",
      "Text:\n",
      "@CNN the End of Times are upon us. Famine War Death Plague. The presence is growing stronger.\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8634571433067322\n",
      "Text:\n",
      "Google Alert: Emergency units simulate a chemical explosion at NU http://t.co/NDgpWYxu6H\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8414732217788696\n",
      "Text:\n",
      "On plus side LOOK AT THE SKY LAST NIGHT IT WAS ABLAZE http://t.co/qqsmshaJ3N\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8188167810440063\n",
      "Text:\n",
      "On Thursday at 00:25 we updated our #kml of 2D and 3D #seismic exploration vessels. #offshore #oil http://t.co/btdjGWeKqx\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8106524348258972\n",
      "Text:\n",
      "http://t.co/eHKLp12yiP Paci?c Media Centre | articles: AUSTRALIA: RSF protests over new security gag over reporting on...\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1, Prob: 0.8096948266029358\n",
      "Text:\n",
      "Do you want to play a game?\n",
      "http://t.co/sQFp6Ecz0i\n",
      "Its a GoogleMaps mashup that calculates the effects of the detonation of nuclear bomb\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the false positives (model predicted 1 when should've been 0)\n",
    "for row in most_wrong[:10].itertuples(): # loop through the top 10 rows (change the index to view different rows)\n",
    "  _, text, target, pred, prob = row\n",
    "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
    "  print(f\"Text:\\n{text}\\n\")\n",
    "  print(\"----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7d345f88-9b4f-42f8-bad3-a0fe1bcd88e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1, Pred: 0, Prob: 0.08835342526435852\n",
      "Text:\n",
      "Dad bought a DVD that looks like a science doc on the front but I read the back and it's actually about the impending biblical apocalypse\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.08612692356109619\n",
      "Text:\n",
      "Perspectives on the Grateful Dead: Critical Writings (Contributions to the Study http://t.co/fmu0fnuMxf http://t.co/AgGRyhVXKr\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.08011748641729355\n",
      "Text:\n",
      "'Money can't buy happiness' is just a lie we tell poor people to keep them from rioting.\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.07660643011331558\n",
      "Text:\n",
      "I feel like if MKayla and Cee ever got in the same room everyone should evacuate because it would be so petty and childish I couldn't deal\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.0688488781452179\n",
      "Text:\n",
      "@gilderoy i wish i was good enough to add flames to my nails im on fire\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.06554054468870163\n",
      "Text:\n",
      "Enjoying a little golf this summer? Take care to avoid injury -- back and shoulder injuries can happen quickly http://t.co/f1R5ISBVks\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.06294148415327072\n",
      "Text:\n",
      "Bloody insomnia again! Grrrr!! #Insomnia\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.05326630547642708\n",
      "Text:\n",
      "@blakeshelton DON'T be a FART ??in a WINDSTORM.FOLLOW ME ALREADY. JEEZ.\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.0457548163831234\n",
      "Text:\n",
      "Reddit Will Now Quarantine Offensive Content http://t.co/WosYPVQUFI http://t.co/XW8SDS1Tjp\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0, Prob: 0.03713306784629822\n",
      "Text:\n",
      "Reddit Will Now QuarantineÛ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the most wrong false negatives (model predicted 0 when should've predict 1)\n",
    "for row in most_wrong[-10:].itertuples():\n",
    "  _, text, target, pred, prob = row\n",
    "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
    "  print(f\"Text:\\n{text}\\n\")\n",
    "  print(\"----\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "ml_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
